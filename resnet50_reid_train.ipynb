{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCud0T9nn1ey",
        "outputId": "ded8cd0a-d9d3-472b-ed9c-3d7d28409405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'deepdrone'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), 961 bytes | 961.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b main2 https://github.com/wadi-sudo/deepdrone.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip deepdrone/data.zip"
      ],
      "metadata": {
        "id": "hOspTJOAoKaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the path to your dataset and the transforms to apply to each image\n",
        "train_data_path = \"/content/data-10classes/train\"\n",
        "test_data_path = \"/content/data-10classes/test\"\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(root=test_data_path, transform=transform_test)\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Define the data loaders for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace the last layer with a new layer that predicts the rotation angle\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 10)  # Replace 4 with the number of rotation angles\n",
        "\n",
        "# Define the loss function and optimizer for training\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, _ in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, torch.arange(4).repeat(batch_size//4))  # Define the rotation angle labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} train loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"/content/model.pth\")\n"
      ],
      "metadata": {
        "id": "rcKZ4-DxoNNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the path to your dataset and the transforms to apply to each image\n",
        "train_data_path = \"/content/data-10classes/train\"\n",
        "test_data_path = \"/content/data-10classes/test\"\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(root=test_data_path, transform=transform_test)\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Define the data loaders for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace the last layer with a new layer that predicts the rotation angle\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 10)  # Replace 4 with the number of rotation angles\n",
        "\n",
        "# Define the loss function and optimizer for training\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, _ in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, torch.arange(4).repeat(batch_size//4))  # Define the rotation angle labels\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} train loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"/content/model.pth\")\n"
      ],
      "metadata": {
        "id": "WqmIRbYh2dRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the path to your dataset and the transforms to apply to each image\n",
        "train_data_path = \"/content/data-10classes/train\"\n",
        "test_data_path = \"/content/data-10classes/test\"\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(root=test_data_path, transform=transform_test)\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Define the data loaders for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace the last layer with a new layer that predicts the rotation angle\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 10)  # Replace 4 with the number of rotation angles\n",
        "\n",
        "# Define the loss function and optimizer for training\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Use the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} train loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"/content/model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtiEJR0oBOnh",
        "outputId": "ef71ba24-299a-4b5c-b5df-4341b1cdc284"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train loss: 1.2811\n",
            "Epoch 2 train loss: 0.8509\n",
            "Epoch 3 train loss: 0.7506\n",
            "Epoch 4 train loss: 0.6891\n",
            "Epoch 5 train loss: 0.6507\n",
            "Epoch 6 train loss: 0.6288\n",
            "Epoch 7 train loss: 0.6100\n",
            "Epoch 8 train loss: 0.5903\n",
            "Epoch 9 train loss: 0.5748\n",
            "Epoch 10 train loss: 0.5583\n"
          ]
        }
      ]
    }
  ]
}